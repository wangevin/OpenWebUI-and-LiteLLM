# OpenWebUI-and-LiteLLM
Simple Documentation of exploration into Open WebUI and LiteLLM

## Useful URLs
- [How to Install Ollama, Docker, and Open WebUI on Linux (Ubuntu)](https://www.youtube.com/watch?v=TsTJVd9LciY)
- [Iâ€™m changing how I use AI (Open WebUI + LiteLLM) ](https://www.youtube.com/watch?v=nQCOTzS5oU0)
- [How to host Open WebUI locally (self-hosted AI Hub)](https://www.youtube.com/watch?v=JJ_0-pAOIEk)
- [Context, not prompts. The missing piece in effective AI-assisted development](https://butschster.medium.com/context-not-prompts-the-missing-piece-in-effective-ai-assisted-development-080f90174953)
- [DIY AI Infrastructure: Build Your Own Privacy-Preserving AI at Home](https://www.youtube.com/watch?v=BvCOZrqGyNU)
- [EASIEST Way to Fine-Tune a LLM and Use It With Ollama](https://www.youtube.com/watch?v=pxhkDaKzBaY)

## Requirements

### LiteLLM Install Requirements
- Python: Python 3.7 or higher is required
- Database (for Proxy): For the LiteLLM Proxy, a database like PostgreSQL is required for features like spend tracking and virtual key management

### Open WebUI Install Requirements
- Docker
- Ollama
- Python 3.11 or higher if using `pip`
- A GPU

## Step 1: Install Docker
- [Install Docker on Ubuntu 24.04](./Docker.md)

## Step 2: 